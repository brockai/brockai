{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/brock/Desktop/brockai/examples/openai/amazon-food-review-qa.ipynb Cell 1\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brock/Desktop/brockai/examples/openai/amazon-food-review-qa.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenai\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAI\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brock/Desktop/brockai/examples/openai/amazon-food-review-qa.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mOPENAI_KEY\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/brock/Desktop/brockai/examples/openai/amazon-food-review-qa.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m client \u001b[39m=\u001b[39m OpenAI(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brock/Desktop/brockai/examples/openai/amazon-food-review-qa.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     api_key\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mgetenv(\u001b[39m\"\u001b[39;49m\u001b[39mOPENAI_KEY\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brock/Desktop/brockai/examples/openai/amazon-food-review-qa.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brock/Desktop/brockai/examples/openai/amazon-food-review-qa.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m display\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brock/Desktop/brockai/examples/openai/amazon-food-review-qa.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcosine_similarity\u001b[39m(a, b):\n",
      "File \u001b[0;32m~/anaconda3/envs/brockai/lib/python3.11/site-packages/openai/_client.py:93\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m     91\u001b[0m     api_key \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m api_key \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     )\n\u001b[1;32m     96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m api_key\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m organization \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Define shared function calls\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import List\n",
    "from scipy import spatial\n",
    "from openai import OpenAI\n",
    "print(os.getenv(\"OPENAI_KEY\"))\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_KEY\")\n",
    ")\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"): # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "def search_docs(df, user_query, top_n=4, to_print=True):\n",
    "    embedding = get_embedding(\n",
    "        user_query,\n",
    "        model=\"text-embedding-ada-002\" # model should be set to the deployment name you chose when you deployed the text-embedding-ada-002 (Version 2) model\n",
    "    )\n",
    "    df[\"similarities\"] = df.ada_v2.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )\n",
    "    if to_print:\n",
    "        display(res)\n",
    "    return res\n",
    "\n",
    "def query(_pipeline, question):\n",
    "    params = {}\n",
    "    results = _pipeline.run(question, params=params)\n",
    "    return results\n",
    "\n",
    "# taken from old release: https://github.com/openai/openai-python/blob/release-v0.28.1/openai/embeddings_utils.py\n",
    "\n",
    "def distances_from_embeddings(\n",
    "    query_embedding: List[float],\n",
    "    embeddings: List[List[float]],\n",
    "    distance_metric=\"cosine\",\n",
    ") -> List[List]:\n",
    "    \"\"\"Return the distances between a query embedding and a list of embeddings.\"\"\"\n",
    "    distance_metrics = {\n",
    "        \"cosine\": spatial.distance.cosine,\n",
    "        \"L1\": spatial.distance.cityblock,\n",
    "        \"L2\": spatial.distance.euclidean,\n",
    "        \"Linf\": spatial.distance.chebyshev,\n",
    "    }\n",
    "    distances = [\n",
    "        distance_metrics[distance_metric](query_embedding, embedding)\n",
    "        for embedding in embeddings\n",
    "    ]\n",
    "    return distances\n",
    "\n",
    "\n",
    "def indices_of_nearest_neighbors_from_distances(distances) -> np.ndarray:\n",
    "    \"\"\"Return a list of indices of nearest neighbors from a list of distances.\"\"\"\n",
    "    return np.argsort(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model parameters\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
    "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'ProductId', 'UserId', 'Score', 'Summary', 'Text', 'combined'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset, combine Summary and Content\n",
    "import pandas as pd\n",
    "\n",
    "input_datapath = \"ingest/Reviews.csv\"  # to save space, we provide a pre-filtered dataset\n",
    "df = pd.read_csv(input_datapath, index_col=0)\n",
    "df = df[[\"Time\", \"ProductId\", \"UserId\", \"Score\", \"Summary\", \"Text\"]]\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df[\"combined\"] = (\n",
    "    \"Title: \" + df.Summary.str.strip() + \"; Content: \" + df.Text.str.strip()\n",
    ")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subsample to 1k most recent reviews and remove samples that are to long\n",
    "import tiktoken\n",
    "\n",
    "top_n = 1000\n",
    "df = df.sort_values(\"Time\").tail(top_n * 2)  # first cut to first 2k entries, assuming less than half will be filtered out\n",
    "df.drop(\"Time\", axis=1, inplace=True)\n",
    "\n",
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "\n",
    "# omit reviews that are too long to embed\n",
    "df[\"n_tokens\"] = df.combined.apply(lambda x: len(encoding.encode(x)))\n",
    "df = df[df.n_tokens <= max_tokens].tail(top_n)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create embeddings\n",
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_KEY\")\n",
    ")\n",
    "\n",
    "from embeddings import get_embedding\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "# This may take a few minutes\n",
    "df[\"embedding\"] = df.combined.apply(lambda x: get_embedding(x, embedding_model))\n",
    "df.to_csv(\"processed/fine_food_reviews_with_embeddings_1k.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question and distance embeddings to provide context\n",
    "\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "\n",
    "def create_context(\n",
    "    question, df, max_len=1800, size=\"ada\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a context for a question by finding the most similar context from the dataframe\n",
    "    \"\"\"\n",
    "    # Get the embeddings for the question\n",
    "    q_embeddings = client.embeddings.create(input=question, model=embedding_model).data[0].embedding\n",
    "    \n",
    "    # Get the distances from the embeddings\n",
    "    df['distances'] = distances_from_embeddings(q_embeddings, df['embedding'].values, distance_metric='cosine')\n",
    "    \n",
    "    returns = []\n",
    "    cur_len = 0\n",
    "\n",
    "    # Sort by distance and add the text to the context until the context is too long\n",
    "    for i, row in df.sort_values('distances', ascending=True).iterrows():\n",
    "\n",
    "        # Add the length of the text to the current length\n",
    "        cur_len += row['n_tokens'] + 4\n",
    "\n",
    "        # If the context is too long, break\n",
    "        if cur_len > max_len:\n",
    "            break\n",
    "\n",
    "        # Else add it to the text that is being returned\n",
    "        returns.append(row[\"Text\"])\n",
    "\n",
    "    # Return the context\n",
    "    return \"\\n\\n###\\n\\n\".join(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get context, create answer\n",
    "def answer_question(\n",
    "    df,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    question=\"Am I allowed to publish model outputs to Twitter, without a human review?\",\n",
    "    max_len=1800,\n",
    "    size=\"ada\",\n",
    "    debug=False,\n",
    "    max_tokens=150,\n",
    "    stop_sequence=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Answer a question based on the most similar context from the dataframe texts\n",
    "    \"\"\"\n",
    "    context = create_context(\n",
    "        question,\n",
    "        df,\n",
    "        max_len=max_len,\n",
    "        size=size,\n",
    "    )\n",
    "    \n",
    "    # If debug, print the raw model response\n",
    "    if debug:\n",
    "        print(\"Context:\\n\" + context)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    try:\n",
    "        # Create a chat completion using the question and context\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Answer the question based on the context below, and if the question can't be answered based on the context, say \\\"I don't know\\\"\\n\\n\"},\n",
    "                {\"role\": \"user\", f\"content\": \"Context: {context}\\n\\n---\\n\\nQuestion: {question}\\nAnswer:\"}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=stop_sequence,\n",
    "        )\n",
    "        return response.choices[0].message.strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Great coffee at a good price. I'm a subscription buyer and I buy this month after month. What more can I say?\n",
      "\n",
      "###\n",
      "\n",
      "Great coffee at a good price. I'm a subscription buyer and I buy this month after month. What more can I say?\n",
      "\n",
      "###\n",
      "\n",
      "Great coffee at a good price. I'm a subscription buyer and I buy this month after month. What more can I say?\n",
      "\n",
      "###\n",
      "\n",
      "Great coffee at a good price. I'm a subscription buyer and I buy this month after month. What more can I say?\n",
      "\n",
      "###\n",
      "\n",
      "I was very happy to find this deal.  Good price and excellent coffee. Gets my morning off to a good start.\n",
      "\n",
      "###\n",
      "\n",
      "San Francisco Bay Coffee Company makes the best coffee for the Kuerig by far.  It's also half the price.  It's always nice to have someone break a monopoly.\n",
      "\n",
      "###\n",
      "\n",
      "This is the best coffee ever! Wish I could order a box of 100 at a time as we go thru a box of 80 in about a month and a half. Buying it online is soooo much cheaper than buying at the grocery store.\n",
      "\n",
      "###\n",
      "\n",
      "In my opinion this is the best coffee ever!  I've been drinking coffee for 50 plus years and this is what I serve to myself and friends.  However, I wish I could find this grind in a pound size, so I could make a full pot rather than just a single cup.\n",
      "\n",
      "###\n",
      "\n",
      "We love this coffee. We are not coffee connoisseurs but do enjoy a good cup of Joe. It works wonderfully in our french press and makes a nice, fresh, coffee shop grade cup.\n",
      "\n",
      "###\n",
      "\n",
      "A bit pricey once you add the S & H but this is one of the best flavored coffees I have tasted.  Got my daughter hooked on it too!\n",
      "\n",
      "###\n",
      "\n",
      "Tully's coffee is the smoothest coffee on the market. The Kona blend is our favorite. The price is well worth the enjoyment we have with every delicious cup!\n",
      "\n",
      "###\n",
      "\n",
      "I love this coffee!  And such a great price.  Will buy more when I am running out which will be soon.\n",
      "\n",
      "###\n",
      "\n",
      "Nespresso makes GREAT coffee and GREAT machines. I switched over to a Nespresso machine 7 years ago and have never looked back. I save a small fortune every year by making my lattes at home.<br /><br />That being said, the Nespresso capsule offers posted here are from a third party who is putting a large additional margin on their price.<br /><br />You can order the same products online from Nespresso for approx $0.55 each (half the price here).\n",
      "\n",
      "###\n",
      "\n",
      "I have used Alessi Decaffenated Caffe'Expresso for years.  It is sometimes difficult to find at local gracery stores and specility coffee stores are far too expensive.  It makes great expresso and excellent caffe' latte. The price on Amazon is excellent.  I buy it in a pack of six and price is even better.\n",
      "\n",
      "###\n",
      "\n",
      "This coffee has a full body and a rich taste. The price is far below the \"other\" coffee in the K cup and does not use as much plastic.\n",
      "\n",
      "###\n",
      "\n",
      "This Green Mountain dark magic coffee is just what I was looking for. Strong enough taste to enjoy and it gets me going almost immediately. Haven't noticed any after taste and buying the 120 count it pans out to like $.61 a cup. Try it you'll like it.\n",
      "\n",
      "###\n",
      "\n",
      "This is the best way to buy coffee for my office. Least expensive way to buy convenience with harder to find flavor and brand.  I also buy this way for home.\n",
      "\n",
      "###\n",
      "\n",
      "This is the best way to buy coffee for my office. Least expensive way to buy convenience with harder to find flavor and brand.  I also buy this way for home.\n",
      "\n",
      "###\n",
      "\n",
      "This is the best way to buy coffee for my office. Least expensive way to buy convenience with harder to find flavor and brand.  I also buy this way for home.\n",
      "\n",
      "###\n",
      "\n",
      "We enjoyed the Brooklyn K Cups very much. The price was right and it was very convenient to receive by mail. We would definitely consider ordering again.\n",
      "\n",
      "###\n",
      "\n",
      "I thought I'd splurge and try this coffee.  It costs much more than other decaf K-Cup options.  But I hoped that meant it was better coffee.  It IS better coffee.  I've never had a better cup of coffee than this.  It is excellent when compared to any other decaf or regular coffee I've tried.<br /><br />If you like BOLD, FLAVORFUL decaf coffee try this coffee and you'll really like it.\n",
      "\n",
      "###\n",
      "\n",
      "I thought I'd splurge and try this coffee.  It costs much more than other decaf K-Cup options.  But I hoped that meant it was better coffee.  It IS better coffee.  I've never had a better cup of coffee than this.  It is excellent when compared to any other decaf or regular coffee I've tried.<br /><br />If you like BOLD, FLAVORFUL decaf coffee try this coffee and you'll really like it.\n",
      "\n",
      "###\n",
      "\n",
      "I thought I'd splurge and try this coffee.  It costs much more than other decaf K-Cup options.  But I hoped that meant it was better coffee.  It IS better coffee.  I've never had a better cup of coffee than this.  It is excellent when compared to any other decaf or regular coffee I've tried.<br /><br />If you like BOLD, FLAVORFUL decaf coffee try this coffee and you'll really like it.\n",
      "\n",
      "###\n",
      "\n",
      "So my wife is a latte freak, and nursing, so decaf is the approved type.  After the Senseo left the market, I struggled and found the <a href=\"http://www.amazon.com/gp/product/B0047BIWSK\">Aerobie AeroPress Coffee and Espresso Maker</a> which is like a French Press for the 21st century.  After getting our recipe figured out, my wife, who's been buying Venti Decaf Latte's at $4 a pop almost daily for years now declares that Seattle's best Level 3 Decaf in her home-made Latte is the best coffee she can get.  We've tried other bands, and this is her favorite, hands down!\n",
      "\n",
      "###\n",
      "\n",
      "Nespresso makes GREAT coffee and GREAT machines. I switched over to a Nespresso machine 7 years ago and have never looked back. I save a small fortune every year by making my lattes at home.<br /><br />That being said, the Nespresso capsule offers posted here are from a third party who is putting a large additional margin on their price.<br /><br />You can order the same products online from Nespresso for approx $0.55 each (half the price here).\n",
      "\n",
      "\n",
      "\n",
      "'ChatCompletionMessage' object has no attribute 'strip'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(df.columns)\n",
    "\n",
    "answer_question(df, question=\"What is the best price for coffee?\", debug=True)\n",
    "\n",
    "# answer_question(df, question=\"What is the best coffee?\")\n",
    "\n",
    "# answer_question(df, question=\"Whoo sold the most coffee?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
